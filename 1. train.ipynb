{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "device = \"cuda\"\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"/media/bhux/alpha/xsd_mvp/test/\"\n",
    "\n",
    "# uniform, lg, gaussian\n",
    "\n",
    "NUMERICAL = 12\n",
    "CATEGORICAL = 0\n",
    "\n",
    "INFILLING_TYPE = ''\n",
    "NOISE_TYPE = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def m(v):\n",
    "    nonnull = v[np.isnan(v) == False]\n",
    "    return np.mean(nonnull)\n",
    "\n",
    "def std(v):\n",
    "    nonnull = v[np.isnan(v) == False]\n",
    "    return np.std(nonnull)\n",
    "\n",
    "def infill_null(v):\n",
    "    v[np.isnan(v)] = 0\n",
    "    return v\n",
    "\n",
    "def remove_outliers(lists):\n",
    "    b = np.ones(lists[0].shape)\n",
    "\n",
    "    for l in lists:\n",
    "        q1 = np.nanquantile(l,0.25)\n",
    "        q3 = np.nanquantile(l,0.75)\n",
    "\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5*iqr\n",
    "        upper = q3 + 1.5*iqr\n",
    "\n",
    "        b = np.logical_and(b, np.logical_or(l > lower , np.isnan(l)))\n",
    "        b = np.logical_and(b, np.logical_or(l < upper , np.isnan(l)))\n",
    "    \n",
    "    return b\n",
    "\n",
    "def norm(v):\n",
    "    nonnull = v[np.isnan(v) == False]\n",
    "    max = np.nanmax(nonnull)\n",
    "    min = np.nanmin(nonnull)\n",
    "\n",
    "    return 2*((v - min) / (max - min))-1\n",
    "\n",
    "def get_local_gaussian(ys, numbins=50):\n",
    "    max = np.nanmax(ys)\n",
    "    min = np.nanmin(ys)\n",
    "    bins = np.linspace(min, max, retstep=numbins)[0]\n",
    "    s_ys = np.array(sorted(ys, reverse=True))\n",
    "\n",
    "    d, m, s = [], [], []\n",
    "    for i in range(numbins-1):\n",
    "        low = bins[i]\n",
    "        high = bins[i+1]\n",
    "        tbool = np.logical_and(low<=s_ys, s_ys<=high)\n",
    "        data = s_ys[tbool]\n",
    "        d.append(len(data))\n",
    "        m.append(data.mean() if not np.isnan(data.mean()) else low)\n",
    "        s.append(data.std() if not np.isnan(data.std()) else 0.01)\n",
    "    d = np.array(d) / sum(d)\n",
    "\n",
    "    return d, np.array(m), np.array(s)\n",
    "\n",
    "def convert_categorical(ys, numbins=50):\n",
    "    max = np.nanmax(ys)\n",
    "    min = np.nanmin(ys)\n",
    "    bins = np.linspace(min, max, retstep=numbins)[0]\n",
    "    s = np.array(sorted(enumerate(ys), key=lambda x:x[1]))\n",
    "    s_inds = s[:,0].astype(int)\n",
    "    s_ys = s[:,1]\n",
    "    \n",
    "    \n",
    "    nys = ys\n",
    "    for i in range(numbins-1):\n",
    "        low = bins[i]\n",
    "        high = bins[i+1]\n",
    "        tbool = np.logical_and(low<=s_ys, s_ys<=high)\n",
    "        \n",
    "        if sum(tbool) > 1:\n",
    "            nys[np.array(s_inds[tbool])] = i+1\n",
    "\n",
    "    print(i+1)\n",
    "    nys[np.isnan(nys)] = 0\n",
    "    return nys\n",
    "\n",
    "def sample_local_gaussian(v, numbins=50):\n",
    "    d,m,s = get_local_gaussian(v, numbins=numbins)\n",
    "    num = sum(np.isnan(v))\n",
    "\n",
    "    samples = np.random.choice(numbins-1, num, p=d)\n",
    "    rand_n = np.random.randn(num)\n",
    "\n",
    "    adjust = m[samples] + 1.2 * rand_n *s[samples]\n",
    "    \n",
    "    # override \n",
    "    #adjust = np.zeros(adjust.shape)\n",
    "    \n",
    "    if INFILLING_TYPE == \"zeros\":\n",
    "        adjust = np.zeros(adjust.shape)\n",
    "\n",
    "    if INFILLING_TYPE == \"uniform\":\n",
    "        adjust = np.random.uniform(low=-1.0, high=1.0, size=adjust.shape)\n",
    "\n",
    "    if INFILLING_TYPE == \"gaussian\":\n",
    "        adjust = np.random.normal(size=adjust.shape)\n",
    "\n",
    "    v[np.isnan(v)] = adjust\n",
    "    return v, (d,m,s)\n",
    "\n",
    "\n",
    "def sample_noise(b, dmss, numbins=50):\n",
    "    if NOISE_TYPE == \"uniform\":\n",
    "        return np.random.uniform(low=-1.0, high=1.0, size=(b,NUMERICAL))\n",
    "    \n",
    "    if NOISE_TYPE == \"gaussian\":\n",
    "        return np.random.normal(size=(b,NUMERICAL))\n",
    "\n",
    "    vs = []\n",
    "    for d,m,s in dmss:\n",
    "        samples = np.random.choice(numbins-1, b, p=d)\n",
    "        rand_n = np.random.randn(b)\n",
    "        vs.append(m[samples] + 1.2 * rand_n *s[samples])\n",
    "    return np.stack(vs, axis=-1)\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    #assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.array(a)[p], np.array(b)[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28422\n",
      "14\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240524/1209130151.py:49: RuntimeWarning: Mean of empty slice.\n",
      "  m.append(data.mean() if not np.isnan(data.mean()) else low)\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:227: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:219: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "25531\n",
      "2891\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./data/xtended_data_all.csv\"\n",
    "EMB_PATH = \"./data/xtended_emb_all_deberta_pubchem.npy\"\n",
    "\n",
    "f = pd.read_csv(PATH)\n",
    "drug_embeddings = np.load(EMB_PATH)\n",
    "smiles = f['Drug'].values\n",
    "vlists = {\n",
    "    col: f[col].values for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL] \n",
    "}\n",
    "\n",
    "inmask = remove_outliers([v for _,v in vlists.items()])\n",
    "print(sum(inmask))\n",
    "smiles = smiles[inmask]\n",
    "vlists = {\n",
    "    k: v[inmask] for k,v in vlists.items()\n",
    "}\n",
    "\n",
    "vlists = {\n",
    "    k: norm(v) for k,v in vlists.items()\n",
    "}\n",
    "\n",
    "# for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL]:\n",
    "#     vlists[col+\"_cat\"] = vlists[col]\n",
    "\n",
    "nullmask = np.stack([\n",
    "    np.isnan(v)==False for _,v in vlists.items()\n",
    "    ], axis=-1)\n",
    "\n",
    "dmss = []\n",
    "for k,v in vlists.items():\n",
    "    vlists[k], dms = sample_local_gaussian(v, numbins=15)\n",
    "    dmss.append(dms)\n",
    "\n",
    "for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL]:\n",
    "    vlists[col+\"_cat\"] = convert_categorical(vlists[col], numbins=15)\n",
    "\n",
    "# for col in f.drop(labels=['Drug'], axis=1).columns[NUMERICAL:]:\n",
    "#     nan = np.isnan(vlists[col])\n",
    "#     vlists[col] += 1\n",
    "#     vlists[col][nan] = 0\n",
    "\n",
    "# dmss = []\n",
    "# for k,v in vlists.items():\n",
    "#     dms = get_local_gaussian(v, numbins=50)\n",
    "#     dmss.append(dms)\n",
    "\n",
    "dataset = []\n",
    "for i, gt in enumerate(zip(*[v for _,v in vlists.items()])):\n",
    "    dataset.append({\n",
    "        \"sm\": smiles[i],\n",
    "        \"ft\": drug_embeddings[i],\n",
    "        \"ma\": nullmask[i],\n",
    "        \"gt\": np.array(gt),\n",
    "        \"od\": np.array(gt[NUMERICAL:]),\n",
    "    })\n",
    "    # print(gt)\n",
    "    # print(nullmask[i])\n",
    "    # break\n",
    "\n",
    "valCount = np.sum(nullmask, axis=0)*0.1\n",
    "dataset, rcomb = unison_shuffled_copies(dataset, nullmask)\n",
    "trdataset = []\n",
    "valdataset = []\n",
    "for c, d in zip(rcomb, dataset):\n",
    "    inc = False\n",
    "    for i, j in enumerate(list(c)):\n",
    "        if j and valCount[i] > 0:\n",
    "            valCount[i] -= 1\n",
    "            inc = True\n",
    "    if inc:\n",
    "        valdataset.append(d)\n",
    "    else:\n",
    "        trdataset.append(d)\n",
    "\n",
    "print(len(trdataset))\n",
    "print(len(valdataset))\n",
    "print(len(list(vlists.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GaucamolDataset(Dataset):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "    \n",
    "    def update(self, idx, delta):\n",
    "        item = self.dataset[idx][\"gt\"]\n",
    "        self.dataset[idx][\"gt\"] = item + delta\n",
    "\n",
    "trainset = GaucamolDataset(trdataset)\n",
    "valset = GaucamolDataset(valdataset)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True)\n",
    "steps_per_epoch = len(trainset)\n",
    "DMSS = dmss[:NUMERICAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(diffusion, ema, gamma, dataloader, optimizer, lr_scheduler, two_noise=False):\n",
    "    diffusion.train()\n",
    "    running_loss = 0\n",
    "    global_step = 0\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        ft = batch['ft'].to(device).float()\n",
    "        gt = batch['gt'].to(device).float()\n",
    "        od = batch['od'].to(device).long()\n",
    "        mask = batch['ma'].to(device)\n",
    "        bs = ft.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_multi, loss_gauss = diffusion.mixed_loss(ft, gt, od, mask, DMSS)\n",
    "\n",
    "        loss = loss_multi + loss_gauss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        ema.update_params(gamma)\n",
    "        gamma = ema.update_gamma(global_step)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        global_step += 1\n",
    "    return running_loss/global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import csv\n",
    "from utils import ohe_to_categories\n",
    "\n",
    "def evaluate(e, ema, dataloader):\n",
    "    ema.ema_model.eval()\n",
    "    before_mse = 0\n",
    "    running_mse = 0\n",
    "    global_step = 0\n",
    "    vals = {}\n",
    "    device = 'cuda'\n",
    "    ema.ema_model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            sm = batch['sm']\n",
    "            mask = batch['ma'].repeat(1,2)\n",
    "            ft = batch['ft'].to(device).float()\n",
    "            gt = batch['gt'].to(device).float()\n",
    "            od = batch['od'].to(device).long()\n",
    "            bs = ft.shape[0]\n",
    "\n",
    "            x_in, generated_ys = ema.ema_model.sample(ft, bs, od, DMSS, clip_sample=True)\n",
    "\n",
    "            raw_mse = mean_squared_error(gt[mask].flatten().cpu(), x_in[mask].flatten().cpu())\n",
    "            mse = mean_squared_error(gt[mask].flatten().cpu(), generated_ys[mask].flatten().cpu())\n",
    "\n",
    "            for s, g in zip(sm, list(generated_ys.cpu().numpy())):\n",
    "                vals[s] = g\n",
    "            \n",
    "            before_mse += raw_mse\n",
    "            running_mse += mse\n",
    "            global_step += 1\n",
    "\n",
    "    with open(save_location+'{}_dict.csv'.format(e), 'w') as csv_file:  \n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in vals.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "    return running_mse / global_step, before_mse / global_step\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema import EMA\n",
    "lr = 0.0005\n",
    "wd = 1e-4\n",
    "warmup = 200\n",
    "n_timesteps = 2000\n",
    "n_inference_timesteps = 150\n",
    "num_epochs = 3000\n",
    "update_epochs = 500\n",
    "update_timesteps = int(num_epochs/update_epochs)\n",
    "gamma = 0.994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 62563024\n",
      "torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sdt import SDT\n",
    "from diffusion import GaussianMultinomialDiffusion\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "\n",
    "total_num_steps = (steps_per_epoch * num_epochs)\n",
    "\n",
    "model = SDT(\n",
    "    time_dim = 128,\n",
    "    cond_size = 768,\n",
    "    patch_size = 8,\n",
    "    y_dim = NUMERICAL+15*(NUMERICAL+CATEGORICAL),\n",
    "    dim = 768,\n",
    "    depth = 12,\n",
    "    heads = 12,\n",
    "    mlp_dim = 1024,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    num_classes = 15,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "\n",
    "diffusion = GaussianMultinomialDiffusion(\n",
    "    num_classes = np.array([15 for _ in range(NUMERICAL+CATEGORICAL)]),\n",
    "    num_numerical_features = NUMERICAL,\n",
    "    denoise_fn = model,\n",
    "    device = device,\n",
    ")\n",
    "diffusion.to(device)\n",
    "\n",
    "ema = EMA(diffusion, gamma, total_num_steps)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd,\n",
    "    )\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "        \"cosine\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup,\n",
    "        num_training_steps=total_num_steps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 94/200 [00:23<00:25,  4.12it/s]"
     ]
    }
   ],
   "source": [
    "l = \"\"\n",
    "best_mse = 1\n",
    "loss = 0\n",
    "for e in range(num_epochs):\n",
    "    loss = train(diffusion, ema, gamma, trainloader, optimizer, lr_scheduler)\n",
    "    if (e % 10 == 0) and (e > 0):\n",
    "        mse, bmse = evaluate(e, ema, valloader)\n",
    "        print(e, \"avgloss {}, avgvalmse {}, beforemse: {}\".format(loss, mse, bmse))\n",
    "        l += \"{} avgloss {}, avgvalmse {}, beforemse: {}\\n\".format(e, loss, mse, bmse)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            torch.save({\n",
    "                'e': e,\n",
    "                'ema_model': ema.ema_model.state_dict(),\n",
    "                'model': diffusion.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, save_location+\"best_model.pt\")\n",
    "    else:\n",
    "        print(e, \"avgloss {}\".format(loss))\n",
    "        l += \"{} avgloss {}\\n\".format(e, loss)\n",
    "\n",
    "    # if ((e % update_epochs  == 0) and e > 500):\n",
    "    #     trainloader = update(int((num_epochs-e) / update_epochs), ema, updateloader, trainset, ns, update_timesteps)\n",
    "\n",
    "    with open(save_location+'output.txt', 'w') as file:\n",
    "        file.write(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2pk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
