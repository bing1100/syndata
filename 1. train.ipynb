{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "device = \"cuda\"\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"/media/bhux/alpha/xsd_mvp/test/\"\n",
    "\n",
    "# uniform, lg, gaussian\n",
    "\n",
    "NUMERICAL = 12\n",
    "CATEGORICAL = 0\n",
    "\n",
    "INFILLING_TYPE = ''\n",
    "NOISE_TYPE = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28444\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_346056/1209130151.py:49: RuntimeWarning: Mean of empty slice.\n",
      "  m.append(data.mean() if not np.isnan(data.mean()) else low)\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:227: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:219: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "25560\n",
      "2884\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from utils import remove_outliers, norm, sample_local_gaussian, convert_categorical, unison_shuffled_copies\n",
    "\n",
    "PATH = \"./data/xtended_data_all.csv\"\n",
    "EMB_PATH = \"./data/xtended_emb_all_deberta_pubchem.npy\"\n",
    "\n",
    "f = pd.read_csv(PATH)\n",
    "drug_embeddings = np.load(EMB_PATH)\n",
    "smiles = f['Drug'].values\n",
    "vlists = {\n",
    "    col: f[col].values for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL] \n",
    "}\n",
    "\n",
    "inmask = remove_outliers([v for _,v in vlists.items()])\n",
    "print(sum(inmask))\n",
    "smiles = smiles[inmask]\n",
    "vlists = {\n",
    "    k: v[inmask] for k,v in vlists.items()\n",
    "}\n",
    "\n",
    "vlists = {\n",
    "    k: norm(v) for k,v in vlists.items()\n",
    "}\n",
    "\n",
    "# for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL]:\n",
    "#     vlists[col+\"_cat\"] = vlists[col]\n",
    "\n",
    "nullmask = np.stack([\n",
    "    np.isnan(v)==False for _,v in vlists.items()\n",
    "    ], axis=-1)\n",
    "\n",
    "dmss = []\n",
    "for k,v in vlists.items():\n",
    "    vlists[k], dms = sample_local_gaussian(v, numbins=15)\n",
    "    dmss.append(dms)\n",
    "\n",
    "for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL]:\n",
    "    vlists[col+\"_cat\"] = convert_categorical(vlists[col], numbins=15)\n",
    "\n",
    "# for col in f.drop(labels=['Drug'], axis=1).columns[NUMERICAL:]:\n",
    "#     nan = np.isnan(vlists[col])\n",
    "#     vlists[col] += 1\n",
    "#     vlists[col][nan] = 0\n",
    "\n",
    "# dmss = []\n",
    "# for k,v in vlists.items():\n",
    "#     dms = get_local_gaussian(v, numbins=50)\n",
    "#     dmss.append(dms)\n",
    "\n",
    "dataset = []\n",
    "for i, gt in enumerate(zip(*[v for _,v in vlists.items()])):\n",
    "    dataset.append({\n",
    "        \"sm\": smiles[i],\n",
    "        \"ft\": drug_embeddings[i],\n",
    "        \"ma\": nullmask[i],\n",
    "        \"gt\": np.array(gt),\n",
    "        \"od\": np.array(gt[NUMERICAL:]),\n",
    "    })\n",
    "    # print(gt)\n",
    "    # print(nullmask[i])\n",
    "    # break\n",
    "\n",
    "valCount = np.sum(nullmask, axis=0)*0.1\n",
    "dataset, rcomb = unison_shuffled_copies(dataset, nullmask)\n",
    "trdataset = []\n",
    "valdataset = []\n",
    "for c, d in zip(rcomb, dataset):\n",
    "    inc = False\n",
    "    for i, j in enumerate(list(c)):\n",
    "        if j and valCount[i] > 0:\n",
    "            valCount[i] -= 1\n",
    "            inc = True\n",
    "    if inc:\n",
    "        valdataset.append(d)\n",
    "    else:\n",
    "        trdataset.append(d)\n",
    "\n",
    "print(len(trdataset))\n",
    "print(len(valdataset))\n",
    "print(len(list(vlists.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GaucamolDataset(Dataset):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "    \n",
    "    def update(self, idx, delta):\n",
    "        item = self.dataset[idx][\"gt\"]\n",
    "        self.dataset[idx][\"gt\"] = item + delta\n",
    "\n",
    "trainset = GaucamolDataset(trdataset)\n",
    "valset = GaucamolDataset(valdataset)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True)\n",
    "steps_per_epoch = len(trainset)\n",
    "DMSS = dmss[:NUMERICAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(diffusion, ema, gamma, dataloader, optimizer, lr_scheduler, two_noise=False):\n",
    "    diffusion.train()\n",
    "    running_loss = 0\n",
    "    global_step = 0\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        ft = batch['ft'].to(device).float()\n",
    "        gt = batch['gt'].to(device).float()\n",
    "        od = batch['od'].to(device).long()\n",
    "        mask = batch['ma'].to(device)\n",
    "        bs = ft.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_multi, loss_gauss = diffusion.mixed_loss(ft, gt, od, mask, DMSS)\n",
    "\n",
    "        loss = loss_multi + loss_gauss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        ema.update_params(gamma)\n",
    "        gamma = ema.update_gamma(global_step)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        global_step += 1\n",
    "    return running_loss/global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import csv\n",
    "from utils import ohe_to_categories\n",
    "\n",
    "def evaluate(e, ema, dataloader):\n",
    "    ema.ema_model.eval()\n",
    "    before_mse = 0\n",
    "    running_mse = 0\n",
    "    global_step = 0\n",
    "    vals = {}\n",
    "    device = 'cuda'\n",
    "    ema.ema_model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            sm = batch['sm']\n",
    "            mask = batch['ma'].repeat(1,2)\n",
    "            ft = batch['ft'].to(device).float()\n",
    "            gt = batch['gt'].to(device).float()\n",
    "            od = batch['od'].to(device).long()\n",
    "            bs = ft.shape[0]\n",
    "\n",
    "            x_in, generated_ys = ema.ema_model.sample(ft, bs, od, DMSS, clip_sample=True)\n",
    "\n",
    "            raw_mse = mean_squared_error(gt[mask].flatten().cpu(), x_in[mask].flatten().cpu())\n",
    "            mse = mean_squared_error(gt[mask].flatten().cpu(), generated_ys[mask].flatten().cpu())\n",
    "\n",
    "            for s, g in zip(sm, list(generated_ys.cpu().numpy())):\n",
    "                vals[s] = g\n",
    "            \n",
    "            before_mse += raw_mse\n",
    "            running_mse += mse\n",
    "            global_step += 1\n",
    "\n",
    "    with open(save_location+'{}_dict.csv'.format(e), 'w') as csv_file:  \n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in vals.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "    return running_mse / global_step, before_mse / global_step\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema import EMA\n",
    "lr = 0.008744566281316077\n",
    "wd = 9.878451251508394e-05\n",
    "warmup = 50\n",
    "n_timesteps = 2000\n",
    "n_inference_timesteps = 150\n",
    "num_epochs = 3000\n",
    "update_epochs = 500\n",
    "update_timesteps = int(num_epochs/update_epochs)\n",
    "gamma = 0.9983421770781913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 62563024\n",
      "torch.Size([180])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sdt import SDT\n",
    "from diffusion import GaussianMultinomialDiffusion\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "\n",
    "total_num_steps = (steps_per_epoch * num_epochs)\n",
    "\n",
    "model = SDT(\n",
    "    time_dim = 32,\n",
    "    cond_size = 768,\n",
    "    patch_size = 64,\n",
    "    y_dim = NUMERICAL+16*(NUMERICAL+CATEGORICAL),\n",
    "    dim = 768,\n",
    "    depth = 10,\n",
    "    heads = 9,\n",
    "    mlp_dim = 512,\n",
    "    dropout =  0.06494632653672873,\n",
    "    emb_dropout =  0.06494632653672873,\n",
    "    num_classes = 16,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "\n",
    "diffusion = GaussianMultinomialDiffusion(\n",
    "    num_classes = np.array([16 for _ in range(NUMERICAL+CATEGORICAL)]),\n",
    "    num_numerical_features = NUMERICAL,\n",
    "    denoise_fn = model,\n",
    "    device = device,\n",
    ")\n",
    "diffusion.to(device)\n",
    "\n",
    "ema = EMA(diffusion, gamma, total_num_steps)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=wd,\n",
    "    )\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "        \"cosine_with_restarts\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=warmup,\n",
    "        num_training_steps=total_num_steps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/200 [00:24<00:25,  4.02it/s]"
     ]
    }
   ],
   "source": [
    "l = \"\"\n",
    "best_mse = 1\n",
    "loss = 0\n",
    "for e in range(num_epochs):\n",
    "    loss = train(diffusion, ema, gamma, trainloader, optimizer, lr_scheduler)\n",
    "    if (e % 10 == 0) and (e > 0):\n",
    "        mse, bmse = evaluate(e, ema, valloader)\n",
    "        print(e, \"avgloss {}, avgvalmse {}, beforemse: {}\".format(loss, mse, bmse))\n",
    "        l += \"{} avgloss {}, avgvalmse {}, beforemse: {}\\n\".format(e, loss, mse, bmse)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            torch.save({\n",
    "                'e': e,\n",
    "                'ema_model': ema.ema_model.state_dict(),\n",
    "                'model': diffusion.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, save_location+\"best_model.pt\")\n",
    "    else:\n",
    "        print(e, \"avgloss {}\".format(loss))\n",
    "        l += \"{} avgloss {}\\n\".format(e, loss)\n",
    "\n",
    "    # if ((e % update_epochs  == 0) and e > 500):\n",
    "    #     trainloader = update(int((num_epochs-e) / update_epochs), ema, updateloader, trainset, ns, update_timesteps)\n",
    "\n",
    "    with open(save_location+'output.txt', 'w') as file:\n",
    "        file.write(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2pk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
