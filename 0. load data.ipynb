{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Caco2_Wang', 'Lipophilicity_AstraZeneca', 'Solubility_AqSolDB', 'HydrationFreeEnergy_FreeSolv', 'PPBR_AZ', 'VDss_Lombardo', 'Half_Life_Obach', 'Clearance_Hepatocyte_AZ', 'Clearance_Microsome_AZ', 'LD50_Zhu', 'herg_central_hERG_at_1uM', 'herg_central_hERG_at_10uM'])\n"
     ]
    }
   ],
   "source": [
    "from tdc.generation import MolGen\n",
    "from tdc.single_pred import ADME\n",
    "from tdc.single_pred import Tox\n",
    "from tdc.utils import retrieve_label_name_list\n",
    "import pandas as pd\n",
    "\n",
    "path = \"/home/bhux/workplace/drug_discovery/data\"\n",
    "\n",
    "def get_splits(data): \n",
    "    split = data.get_split()\n",
    "    split = [split['train'], split['valid'], split['test']]\n",
    "    split = pd.concat(split)\n",
    "    return split\n",
    "\n",
    "adme_names = [\n",
    "    'Caco2_Wang',   # 906\n",
    "    'Lipophilicity_AstraZeneca',\n",
    "    'Solubility_AqSolDB',\n",
    "    'HydrationFreeEnergy_FreeSolv',\n",
    "    'PPBR_AZ',\n",
    "    'VDss_Lombardo',\n",
    "    'Half_Life_Obach',\n",
    "    'Clearance_Hepatocyte_AZ',\n",
    "    'Clearance_Microsome_AZ',\n",
    "]\n",
    "\n",
    "tox_names = [\n",
    "    'LD50_Zhu',\n",
    "]\n",
    "\n",
    "data_dfs = {}\n",
    "for name in adme_names:\n",
    "    data = ADME(name = name, path=path)\n",
    "    data_dfs[name] = get_splits(data)\n",
    "\n",
    "data = Tox(name = 'LD50_Zhu', path=path)\n",
    "data_dfs['LD50_Zhu'] = get_splits(data)\n",
    "\n",
    "label_list = retrieve_label_name_list('herg_central')\n",
    "for lname in label_list[:-1]: # no inhib\n",
    "    data = Tox(name = 'herg_central', label_name = lname)\n",
    "    data_dfs['herg_central_'+lname] = get_splits(data)\n",
    "\n",
    "print(data_dfs.keys())\n",
    "\n",
    "# categorical adme \n",
    "cat_adme_names = [\n",
    "    # 'PAMPA_NCATS',\n",
    "    # 'HIA_Hou',\n",
    "    # 'Pgp_Broccatelli',\n",
    "    # 'Bioavailability_Ma',\n",
    "    # 'BBB_Martins',\n",
    "    # 'CYP2C19_Veith',\n",
    "    # 'CYP2D6_Veith',\n",
    "    # 'CYP3A4_Veith',\n",
    "    # 'CYP1A2_Veith',\n",
    "    # 'CYP2C9_Veith',\n",
    "    # 'CYP2C9_Substrate_CarbonMangels',\n",
    "    # 'CYP2D6_Substrate_CarbonMangels',\n",
    "    # 'CYP3A4_Substrate_CarbonMangels',\n",
    "]\n",
    "\n",
    "for name in cat_adme_names:\n",
    "    data = ADME(name = name, path=path)\n",
    "    data_dfs[name] = get_splits(data)\n",
    "\n",
    "# cat_tox_names = [\n",
    "#     'AMES',\n",
    "#     'DILI',\n",
    "#     'Skin Reaction',\n",
    "#     'Carcinogens_Lagunin',\n",
    "#     'ClinTox',\n",
    "# ]\n",
    "\n",
    "# for name in cat_tox_names:\n",
    "#     data = Tox(name = name, path=path)\n",
    "#     data_dfs[name] = get_splits(data)\n",
    "\n",
    "# # Tox21 and ToxCast\n",
    "# name = 'Tox21'\n",
    "# label_list = retrieve_label_name_list(name)\n",
    "# for lname in label_list: # no inhib\n",
    "#     data = Tox(name = name, label_name = lname)\n",
    "#     data_dfs[name+lname] = get_splits(data)\n",
    "\n",
    "# name = 'Toxcast'\n",
    "# label_list = retrieve_label_name_list(name)\n",
    "# for lname in label_list[:10]: # no inhib\n",
    "#     data = Tox(name = name, label_name = lname)\n",
    "#     data_dfs[name+lname] = get_splits(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327533\n",
      "dict_keys(['Drug', 'Caco2_Wang', 'Lipophilicity_AstraZeneca', 'Solubility_AqSolDB', 'HydrationFreeEnergy_FreeSolv', 'PPBR_AZ', 'VDss_Lombardo', 'Half_Life_Obach', 'Clearance_Hepatocyte_AZ', 'Clearance_Microsome_AZ', 'LD50_Zhu', 'herg_central_hERG_at_1uM', 'herg_central_hERG_at_10uM'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Caco2_Wang</th>\n",
       "      <th>Lipophilicity_AstraZeneca</th>\n",
       "      <th>Solubility_AqSolDB</th>\n",
       "      <th>HydrationFreeEnergy_FreeSolv</th>\n",
       "      <th>PPBR_AZ</th>\n",
       "      <th>VDss_Lombardo</th>\n",
       "      <th>Half_Life_Obach</th>\n",
       "      <th>Clearance_Hepatocyte_AZ</th>\n",
       "      <th>Clearance_Microsome_AZ</th>\n",
       "      <th>LD50_Zhu</th>\n",
       "      <th>herg_central_hERG_at_1uM</th>\n",
       "      <th>herg_central_hERG_at_10uM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1n[nH]c(C)c1-c1nc2ccccc2[nH]1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2275</td>\n",
       "      <td>0.97548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(#Cc1ccccc1)C[N+]1(CC#Cc2ccccc2)CCCC1.[Br-]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.4346</td>\n",
       "      <td>-55.52842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Br.N=C1c2ccccc2CN1NC(=O)c1cccc(S(=O)(=O)N2CCCC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.4922</td>\n",
       "      <td>13.45668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C=CCSc1nnc(NC(=O)c2ccc(S(=O)(=O)NCC3CCCO3)cc2)s1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0481</td>\n",
       "      <td>13.52548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C(CS(=O)(=O)c1cn(Cc2ccc(F)cc2)c2ccccc12)N1CC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8734</td>\n",
       "      <td>-16.65112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CCc1cccc(NC(=O)c2cccc(S(=O)(=O)N3CCN(C)CC3)c2)c1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.1511</td>\n",
       "      <td>-53.90882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CCOCCCNC(=O)c1cn(CC)c2ccc(S(=O)(=O)N3CCC(C)CC3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2509</td>\n",
       "      <td>-22.63932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CN(CC(=O)NCC1CCCO1)S(=O)(=O)c1cc(Cl)ccc1Cl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9166</td>\n",
       "      <td>-0.78322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CCCCn1c(O)c(/C=C2/C=CC=N2)c(=O)[nH]c1=O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.2141</td>\n",
       "      <td>6.34478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CC(C)C(=O)OCC(=O)Nc1ccc(N=Nc2ccccc2)cc1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8161</td>\n",
       "      <td>4.20108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Drug  Caco2_Wang  \\\n",
       "0                    Cc1n[nH]c(C)c1-c1nc2ccccc2[nH]1         NaN   \n",
       "1       C(#Cc1ccccc1)C[N+]1(CC#Cc2ccccc2)CCCC1.[Br-]         NaN   \n",
       "2  Br.N=C1c2ccccc2CN1NC(=O)c1cccc(S(=O)(=O)N2CCCC...         NaN   \n",
       "3   C=CCSc1nnc(NC(=O)c2ccc(S(=O)(=O)NCC3CCCO3)cc2)s1         NaN   \n",
       "4  O=C(CS(=O)(=O)c1cn(Cc2ccc(F)cc2)c2ccccc12)N1CC...         NaN   \n",
       "5   CCc1cccc(NC(=O)c2cccc(S(=O)(=O)N3CCN(C)CC3)c2)c1         NaN   \n",
       "6  CCOCCCNC(=O)c1cn(CC)c2ccc(S(=O)(=O)N3CCC(C)CC3...         NaN   \n",
       "7         CN(CC(=O)NCC1CCCO1)S(=O)(=O)c1cc(Cl)ccc1Cl         NaN   \n",
       "8            CCCCn1c(O)c(/C=C2/C=CC=N2)c(=O)[nH]c1=O         NaN   \n",
       "9            CC(C)C(=O)OCC(=O)Nc1ccc(N=Nc2ccccc2)cc1         NaN   \n",
       "\n",
       "   Lipophilicity_AstraZeneca  Solubility_AqSolDB  \\\n",
       "0                        NaN                 NaN   \n",
       "1                        NaN                 NaN   \n",
       "2                        NaN                 NaN   \n",
       "3                        NaN                 NaN   \n",
       "4                        NaN                 NaN   \n",
       "5                        NaN                 NaN   \n",
       "6                        NaN                 NaN   \n",
       "7                        NaN                 NaN   \n",
       "8                        NaN                 NaN   \n",
       "9                        NaN                 NaN   \n",
       "\n",
       "   HydrationFreeEnergy_FreeSolv  PPBR_AZ  VDss_Lombardo  Half_Life_Obach  \\\n",
       "0                           NaN      NaN            NaN              NaN   \n",
       "1                           NaN      NaN            NaN              NaN   \n",
       "2                           NaN      NaN            NaN              NaN   \n",
       "3                           NaN      NaN            NaN              NaN   \n",
       "4                           NaN      NaN            NaN              NaN   \n",
       "5                           NaN      NaN            NaN              NaN   \n",
       "6                           NaN      NaN            NaN              NaN   \n",
       "7                           NaN      NaN            NaN              NaN   \n",
       "8                           NaN      NaN            NaN              NaN   \n",
       "9                           NaN      NaN            NaN              NaN   \n",
       "\n",
       "   Clearance_Hepatocyte_AZ  Clearance_Microsome_AZ  LD50_Zhu  \\\n",
       "0                      NaN                     NaN       NaN   \n",
       "1                      NaN                     NaN       NaN   \n",
       "2                      NaN                     NaN       NaN   \n",
       "3                      NaN                     NaN       NaN   \n",
       "4                      NaN                     NaN       NaN   \n",
       "5                      NaN                     NaN       NaN   \n",
       "6                      NaN                     NaN       NaN   \n",
       "7                      NaN                     NaN       NaN   \n",
       "8                      NaN                     NaN       NaN   \n",
       "9                      NaN                     NaN       NaN   \n",
       "\n",
       "   herg_central_hERG_at_1uM  herg_central_hERG_at_10uM  \n",
       "0                    4.2275                    0.97548  \n",
       "1                  -17.4346                  -55.52842  \n",
       "2                   14.4922                   13.45668  \n",
       "3                   15.0481                   13.52548  \n",
       "4                    8.8734                  -16.65112  \n",
       "5                   -7.1511                  -53.90882  \n",
       "6                    7.2509                  -22.63932  \n",
       "7                    0.9166                   -0.78322  \n",
       "8                   29.2141                    6.34478  \n",
       "9                   10.8161                    4.20108  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Populate smiles\n",
    "smiles = []\n",
    "for _, df in data_dfs.items():\n",
    "    smiles.extend(list(df['Drug']))\n",
    "smiles = list(set(smiles))\n",
    "print(len(smiles))\n",
    "\n",
    "# Build dataset\n",
    "lengths = []\n",
    "dataset = {'Drug': smiles}\n",
    "for k, df in data_dfs.items():\n",
    "    df = {v['Drug']: v['Y'] for v in df.to_dict(orient='records')}\n",
    "    dataset[k] = []\n",
    "    for smile in smiles:\n",
    "        dataset[k].append(df.get(smile, np.nan))\n",
    "    lengths.append(len(dataset[k])-sum(np.isnan(np.array(dataset[k]))))\n",
    "\n",
    "print(dataset.keys())\n",
    "\n",
    "df = pd.DataFrame(data=dataset)\n",
    "\n",
    "display(df[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['00000000001', '00100000000', '00100000011', '01000000101', '00000000010', '01000000000', '00100000010', '00000000011', '00000100010', '00001000000', '00100000001', '10000000000', '00000010000', '00000010001', '01001000000', '01000001100', '10000010000', '00000100000', '01001001000', '01101110011', '01101001111', '00001000100', '00001001100', '10000000010', '01001001100', '01000000100', '01000000001', '00110000010', '00110000011', '00000100001', '10100000000', '00110000000', '00000001000', '00010000000', '01001000001', '01000001000', '00100000100', '01110000010', '10110000010', '00000100011', '01100000000', '01000010000', '01100000010', '01001000100', '00000001100', '00001000001', '01101011001', '00000001101', '01000001101', '00101000010', '00000110000', '11101000011', '01001001101', '00001001000', '00100010000', '01001111000', '01100000011', '01101011110', '10000011110', '01100010011', '00101000000', '01001010010', '00001100000', '11100000010', '01000100000', '11001010000', '01101000011', '10110000000', '10100000010', '00001011001', '10001011001', '00000110001', '00100010010', '10000010001', '01001011000', '10001000000', '00100100010', '10110000001', '00100010001', '00100100001', '00000010011', '01100001011', '10000000001', '00000011100', '01010001101', '01001010000', '01000110001', '01100000001', '00000011000', '01101111010', '01001010011', '11001000011', '10100000011', '00100100011', '10100010010', '01000010011', '01000000010', '00100100000', '10100110011', '01000010001', '01000010010', '10000001000', '01101010000', '00000110011', '00100110010', '01001001001', '00001111100', '00001010011', '11001011000', '00100110001', '10100000001', '01100110001', '00000000100', '00001101100', '11001001101', '00000010010', '00100010011', '11000010000', '00000001001', '00001010001', '10001011100', '01000100010', '10110010000', '01000011101', '01001011001', '00010000001', '01000110011', '01100110010', '01001110011', '11101111000', '11000000001', '00001010000', '01101110111', '01000000011', '00001001001', '01001100011', '01000011110', '00110001000', '00110000001', '01000111010', '01101010010', '11000011100', '01100111000', '01101111110', '01001011101', '01101010011', '01110000011', '01000011000', '01100011011', '10000001001', '11101001111', '01100000100', '00000011001', '01101000001', '10001011101', '11101010000', '11000000000', '11101011001', '11100110001', '00001011000', '01101011011', '11110000100', '00010000010', '10001010001', '10000100001', '00001010100', '10001010000', '01001000011', '11001101100', '11100010000', '11001110011', '01000001001', '10000100000', '01100000110', '11100000000', '11101111111', '00001001101', '10100010000', '11100110011', '01100100010', '00001011100', '10100010001', '01101000000', '01001000010', '00001010110', '11101001001', '01100001001', '01110000111', '01100010001', '00101010000', '01100110111', '01100010000', '00100110000', '10110010010', '11001001110', '00001110000', '10000110010', '01101100001', '10000110001', '01100000101', '01000011100', '01101001110', '11001110010', '11100110010', '00001000101', '01101111111', '01001011100', '00101011110', '00000000111', '10000110011', '00001011010', '01101001001', '01101011111', '01100010010', '01111011010', '11100001111', '11101011110', '01001011110', '00101110001', '01101011101', '11100001011', '10000000011', '00100110011', '00101011111', '11101011111', '10100010011', '01000100001', '00110010011', '00100011001', '00101000001', '10101001100', '10010000000', '00001100001', '00110110011', '01000001110', '10000010010', '00101100001', '11101011000', '01100110011', '11001000100', '01100000111', '11100011111', '01001001111', '01100011000', '11001001100', '11110000010', '00100011111', '00000111010', '10000011001', '00001000010', '10100100001', '10100110000', '10001111111', '11100000011', '01100001111', '01100111011', '01000101100', '00000110010', '11111111011', '01001011010', '00000000101', '01000001010', '01001101100', '11000000011', '01001110010', '11101000010', '11000001001', '11000011000', '10001000101', '00000001011', '00100001000', '00101111000', '11001011100', '11101110001', '01100011101', '01100001101', '01101011000', '11001010001', '11101011100', '11000011001', '11000011101'])\n",
      "dict_values([305433, 7176, 187, 5, 4984, 2179, 1420, 158, 12, 386, 315, 686, 282, 37, 414, 178, 10, 919, 59, 1, 2, 22, 68, 9, 235, 236, 262, 262, 27, 14, 25, 202, 75, 98, 22, 92, 1, 3, 4, 4, 29, 17, 11, 121, 70, 41, 1, 13, 13, 1, 26, 1, 28, 35, 19, 1, 21, 3, 1, 4, 2, 1, 2, 3, 3, 1, 2, 3, 8, 1, 1, 6, 4, 5, 1, 1, 11, 2, 11, 4, 2, 3, 30, 1, 1, 12, 2, 16, 3, 3, 2, 1, 3, 4, 3, 4, 19, 19, 1, 4, 4, 3, 5, 4, 3, 2, 1, 1, 2, 2, 8, 4, 17, 1, 1, 10, 7, 1, 5, 1, 1, 1, 1, 1, 3, 5, 1, 2, 2, 2, 2, 4, 2, 8, 6, 1, 1, 1, 11, 1, 2, 1, 1, 3, 2, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 5, 3, 1, 1, 1, 1, 12, 2, 2, 1, 1, 2, 1, 2, 1, 3, 3, 1, 2, 1, 5, 2, 1, 1, 3, 5, 2, 4, 1, 1, 2, 1, 2, 2, 1, 5, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 5, 1, 2, 1, 1, 1, 2, 2, 1, 1, 3, 1, 1, 3, 1, 2, 4, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "combinations = []\n",
    "for row in df.drop(labels=['Drug', 'herg_central_hERG_at_10uM'], axis=1).iterrows():\n",
    "    combinations.append(\"\".join([str(int(np.isnan(v) == False)) for _,v in list(row)[1].items()]))\n",
    "\n",
    "uc = Counter(combinations)\n",
    "print(uc.keys())\n",
    "print(uc.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "cbool = np.array(combinations) != '0'*10 + '1' + '0'*(len(list(uc.keys())[0])-11) #'00000000001000000000000000000000000000000'\n",
    "inc = np.random.choice([i for i, x in enumerate(cbool) if x == False], 7900, replace=False)\n",
    "cbool = [True if i in inc else v for i,v in enumerate(cbool)]\n",
    "\n",
    "fcomb = np.array(combinations)[cbool]\n",
    "fdf = df[cbool]\n",
    "\n",
    "print(len(fdf.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27039\n",
      "2961\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    #assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], p\n",
    "\n",
    "rcomb, perm = unison_shuffled_copies(fcomb, fdf.iloc)\n",
    "lengths[10] = 7900\n",
    "del lengths[11]\n",
    "valCount = np.array(lengths)*0.1\n",
    "\n",
    "trIdx = []\n",
    "valIdx = []\n",
    "for c, p in zip(rcomb, perm):\n",
    "    inc = False\n",
    "    for i, j in enumerate(list(c)):\n",
    "        if j == \"1\" and valCount[i] > 0:\n",
    "            valCount[i] -= 1\n",
    "            inc = True\n",
    "    if inc:\n",
    "        valIdx.append(p)\n",
    "    else:\n",
    "        trIdx.append(p)\n",
    "\n",
    "print(len(trIdx))\n",
    "print(len(valIdx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdf = fdf.iloc[trIdx]\n",
    "valdf = fdf.iloc[valIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, T5EncoderModel, AutoModelForMaskedLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = \"sagawa/PubChem-10m-deberta\"\n",
    "# \"sagawa/PubChem-10m-deberta\"\n",
    "# \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "# \"DeepChem/ChemBERTa-10M-MLM\"\n",
    "# \"sagawa/PubChem-10m-t5-v2\"\n",
    "\n",
    "# \"ncfrey/ChemGPT-4.7M\"\n",
    "# \"RaphaelMourad/Mistral-Chem-v1-417M\"\n",
    "# \"jonghyunlee/ChemBERT_ChEMBL_pretrained\"\n",
    "\n",
    "# Initialize tokenizer and model for drug embeddings\n",
    "drug_tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "drug_model = AutoModel.from_pretrained(model)\n",
    "\n",
    "drug_model.to('cuda')\n",
    "\n",
    "# Function to get drug embeddings from SMILES strings\n",
    "def get_drug_embeddings(smiles_list, tokenizer, model, batch_size=64):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(smiles_list), batch_size)):\n",
    "        batch = smiles_list[i:i+batch_size]\n",
    "        encoding = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        input_ids = encoding[\"input_ids\"].to('cuda')\n",
    "        attention_mask = encoding[\"attention_mask\"].to('cuda')  # Get the attention mask\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Pass both input_ids and attention_mask to the model\n",
    "            output = model(input_ids, attention_mask=attention_mask)\n",
    "            # You can use either the last hidden state or the pooled output\n",
    "            # depending on your requirements. Here we're using the mean of the last hidden state.\n",
    "            embedding = output.last_hidden_state.mean(1)\n",
    "            embeddings.extend(embedding.cpu().numpy())\n",
    "            \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:47<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "# Save train\n",
    "drug_embeddings_split_kd = get_drug_embeddings(list(fdf['Drug']), drug_tokenizer, drug_model)\n",
    "print(len(drug_embeddings_split_kd))\n",
    "np.save(\"./data/xtended_emb_all_deberta_pubchem\", np.array(drug_embeddings_split_kd))\n",
    "fdf.to_csv(\"./data/xtended_data_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:04<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "drug_embeddings_split_kd = get_drug_embeddings(list(valdf['Drug']), drug_tokenizer, drug_model)\n",
    "print(len(drug_embeddings_split_kd))\n",
    "np.save(\"./data/xtended_emb_val_deberta_pubchem\", np.array(drug_embeddings_split_kd))\n",
    "valdf.to_csv(\"./data/xtended_data_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2pk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
