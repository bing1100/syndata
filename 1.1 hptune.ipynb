{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from diffusers.optimization import get_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "device = \"cuda\"\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = \"/media/bhux/alpha/xsd_mvp/test/\"\n",
    "\n",
    "# uniform, lg, gaussian\n",
    "\n",
    "NUMERICAL = 12\n",
    "CATEGORICAL = 0\n",
    "\n",
    "INFILLING_TYPE = ''\n",
    "NOISE_TYPE = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def m(v):\n",
    "    nonnull = v[np.isnan(v) == False]\n",
    "    return np.mean(nonnull)\n",
    "\n",
    "def std(v):\n",
    "    nonnull = v[np.isnan(v) == False]\n",
    "    return np.std(nonnull)\n",
    "\n",
    "def infill_null(v):\n",
    "    v[np.isnan(v)] = 0\n",
    "    return v\n",
    "\n",
    "def remove_outliers(lists):\n",
    "    b = np.ones(lists[0].shape)\n",
    "\n",
    "    for l in lists:\n",
    "        q1 = np.nanquantile(l,0.25)\n",
    "        q3 = np.nanquantile(l,0.75)\n",
    "\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5*iqr\n",
    "        upper = q3 + 1.5*iqr\n",
    "\n",
    "        b = np.logical_and(b, np.logical_or(l > lower , np.isnan(l)))\n",
    "        b = np.logical_and(b, np.logical_or(l < upper , np.isnan(l)))\n",
    "    \n",
    "    return b\n",
    "\n",
    "def norm(v):\n",
    "    nonnull = v[np.isnan(v) == False]\n",
    "    max = np.nanmax(nonnull)\n",
    "    min = np.nanmin(nonnull)\n",
    "\n",
    "    return 2*((v - min) / (max - min))-1\n",
    "\n",
    "def get_local_gaussian(ys, numbins=50):\n",
    "    max = np.nanmax(ys)\n",
    "    min = np.nanmin(ys)\n",
    "    bins = np.linspace(min, max, retstep=numbins)[0]\n",
    "    s_ys = np.array(sorted(ys, reverse=True))\n",
    "\n",
    "    d, m, s = [], [], []\n",
    "    for i in range(numbins-1):\n",
    "        low = bins[i]\n",
    "        high = bins[i+1]\n",
    "        tbool = np.logical_and(low<=s_ys, s_ys<=high)\n",
    "        data = s_ys[tbool]\n",
    "        d.append(len(data))\n",
    "        m.append(data.mean() if not np.isnan(data.mean()) else low)\n",
    "        s.append(data.std() if not np.isnan(data.std()) else 0.01)\n",
    "    d = np.array(d) / sum(d)\n",
    "\n",
    "    return d, np.array(m), np.array(s)\n",
    "\n",
    "def convert_categorical(ys, numbins=50):\n",
    "    max = np.nanmax(ys)\n",
    "    min = np.nanmin(ys)\n",
    "    bins = np.linspace(min, max, retstep=numbins)[0]\n",
    "    s = np.array(sorted(enumerate(ys), key=lambda x:x[1]))\n",
    "    s_inds = s[:,0].astype(int)\n",
    "    s_ys = s[:,1]\n",
    "    \n",
    "    \n",
    "    nys = ys\n",
    "    for i in range(numbins-1):\n",
    "        low = bins[i]\n",
    "        high = bins[i+1]\n",
    "        tbool = np.logical_and(low<=s_ys, s_ys<=high)\n",
    "        \n",
    "        if sum(tbool) > 1:\n",
    "            nys[np.array(s_inds[tbool])] = i+1\n",
    "\n",
    "    print(i+1)\n",
    "    nys[np.isnan(nys)] = 0\n",
    "    return nys\n",
    "\n",
    "def sample_local_gaussian(v, numbins=50):\n",
    "    d,m,s = get_local_gaussian(v, numbins=numbins)\n",
    "    num = sum(np.isnan(v))\n",
    "\n",
    "    samples = np.random.choice(numbins-1, num, p=d)\n",
    "    rand_n = np.random.randn(num)\n",
    "\n",
    "    adjust = m[samples] + 1.2 * rand_n *s[samples]\n",
    "    \n",
    "    # override \n",
    "    #adjust = np.zeros(adjust.shape)\n",
    "    \n",
    "    if INFILLING_TYPE == \"zeros\":\n",
    "        adjust = np.zeros(adjust.shape)\n",
    "\n",
    "    if INFILLING_TYPE == \"uniform\":\n",
    "        adjust = np.random.uniform(low=-1.0, high=1.0, size=adjust.shape)\n",
    "\n",
    "    if INFILLING_TYPE == \"gaussian\":\n",
    "        adjust = np.random.normal(size=adjust.shape)\n",
    "\n",
    "    v[np.isnan(v)] = adjust\n",
    "    return v, (d,m,s)\n",
    "\n",
    "\n",
    "def sample_noise(b, dmss, numbins=50):\n",
    "    if NOISE_TYPE == \"uniform\":\n",
    "        return np.random.uniform(low=-1.0, high=1.0, size=(b,NUMERICAL))\n",
    "    \n",
    "    if NOISE_TYPE == \"gaussian\":\n",
    "        return np.random.normal(size=(b,NUMERICAL))\n",
    "\n",
    "    vs = []\n",
    "    for d,m,s in dmss:\n",
    "        samples = np.random.choice(numbins-1, b, p=d)\n",
    "        rand_n = np.random.randn(b)\n",
    "        vs.append(m[samples] + 1.2 * rand_n *s[samples])\n",
    "    return np.stack(vs, axis=-1)\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    #assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return np.array(a)[p], np.array(b)[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28422\n",
      "14\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_256404/1209130151.py:49: RuntimeWarning: Mean of empty slice.\n",
      "  m.append(data.mean() if not np.isnan(data.mean()) else low)\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:227: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/numpy/_core/_methods.py:219: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "25531\n",
      "2891\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./data/xtended_data_all.csv\"\n",
    "EMB_PATH = \"./data/xtended_emb_all_deberta_pubchem.npy\"\n",
    "\n",
    "f = pd.read_csv(PATH)\n",
    "drug_embeddings = np.load(EMB_PATH)\n",
    "smiles = f['Drug'].values\n",
    "vlists = {\n",
    "    col: f[col].values for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL] \n",
    "}\n",
    "\n",
    "inmask = remove_outliers([v for _,v in vlists.items()])\n",
    "print(sum(inmask))\n",
    "smiles = smiles[inmask]\n",
    "vlists = {\n",
    "    k: v[inmask] for k,v in vlists.items()\n",
    "}\n",
    "\n",
    "vlists = {\n",
    "    k: norm(v) for k,v in vlists.items()\n",
    "}\n",
    "\n",
    "# for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL]:\n",
    "#     vlists[col+\"_cat\"] = vlists[col]\n",
    "\n",
    "nullmask = np.stack([\n",
    "    np.isnan(v)==False for _,v in vlists.items()\n",
    "    ], axis=-1)\n",
    "\n",
    "dmss = []\n",
    "for k,v in vlists.items():\n",
    "    vlists[k], dms = sample_local_gaussian(v, numbins=15)\n",
    "    dmss.append(dms)\n",
    "\n",
    "for col in f.drop(labels=['Drug'], axis=1).columns[:NUMERICAL]:\n",
    "    vlists[col+\"_cat\"] = convert_categorical(vlists[col], numbins=15)\n",
    "\n",
    "# for col in f.drop(labels=['Drug'], axis=1).columns[NUMERICAL:]:\n",
    "#     nan = np.isnan(vlists[col])\n",
    "#     vlists[col] += 1\n",
    "#     vlists[col][nan] = 0\n",
    "\n",
    "# dmss = []\n",
    "# for k,v in vlists.items():\n",
    "#     dms = get_local_gaussian(v, numbins=50)\n",
    "#     dmss.append(dms)\n",
    "\n",
    "dataset = []\n",
    "for i, gt in enumerate(zip(*[v for _,v in vlists.items()])):\n",
    "    dataset.append({\n",
    "        \"sm\": smiles[i],\n",
    "        \"ft\": drug_embeddings[i],\n",
    "        \"ma\": nullmask[i],\n",
    "        \"gt\": np.array(gt),\n",
    "        \"od\": np.array(gt[NUMERICAL:]),\n",
    "    })\n",
    "    # print(gt)\n",
    "    # print(nullmask[i])\n",
    "    # break\n",
    "\n",
    "valCount = np.sum(nullmask, axis=0)*0.1\n",
    "dataset, rcomb = unison_shuffled_copies(dataset, nullmask)\n",
    "trdataset = []\n",
    "valdataset = []\n",
    "for c, d in zip(rcomb, dataset):\n",
    "    inc = False\n",
    "    for i, j in enumerate(list(c)):\n",
    "        if j and valCount[i] > 0:\n",
    "            valCount[i] -= 1\n",
    "            inc = True\n",
    "    if inc:\n",
    "        valdataset.append(d)\n",
    "    else:\n",
    "        trdataset.append(d)\n",
    "\n",
    "print(len(trdataset))\n",
    "print(len(valdataset))\n",
    "print(len(list(vlists.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GaucamolDataset(Dataset):\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "    \n",
    "    def update(self, idx, delta):\n",
    "        item = self.dataset[idx][\"gt\"]\n",
    "        self.dataset[idx][\"gt\"] = item + delta\n",
    "\n",
    "trainset = GaucamolDataset(trdataset)\n",
    "valset = GaucamolDataset(valdataset)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True)\n",
    "steps_per_epoch = len(trainset)\n",
    "DMSS = dmss[:NUMERICAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(diffusion, ema, gamma, dataloader, optimizer, lr_scheduler, two_noise=False):\n",
    "    diffusion.train()\n",
    "    running_loss = 0\n",
    "    global_step = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        ft = batch['ft'].to(device).float()\n",
    "        gt = batch['gt'].to(device).float()\n",
    "        od = batch['od'].to(device).long()\n",
    "        mask = batch['ma'].to(device)\n",
    "        bs = ft.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_multi, loss_gauss = diffusion.mixed_loss(ft, gt, od, mask, DMSS)\n",
    "\n",
    "        loss = loss_multi + loss_gauss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        ema.update_params(gamma)\n",
    "        gamma = ema.update_gamma(global_step)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        global_step += 1\n",
    "    return running_loss/global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import csv\n",
    "from utils import ohe_to_categories\n",
    "\n",
    "def evaluate(e, ema, dataloader):\n",
    "    ema.ema_model.eval()\n",
    "    before_mse = 0\n",
    "    running_mse = 0\n",
    "    global_step = 0\n",
    "    vals = {}\n",
    "    device = 'cuda'\n",
    "    ema.ema_model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            sm = batch['sm']\n",
    "            mask = batch['ma'].repeat(1,2)\n",
    "            ft = batch['ft'].to(device).float()\n",
    "            gt = batch['gt'].to(device).float()\n",
    "            od = batch['od'].to(device).long()\n",
    "            bs = ft.shape[0]\n",
    "\n",
    "            x_in, generated_ys = ema.ema_model.sample(ft, bs, od, DMSS, clip_sample=True)\n",
    "\n",
    "            raw_mse = mean_squared_error(gt[mask].flatten().cpu(), x_in[mask].flatten().cpu())\n",
    "            mse = mean_squared_error(gt[mask].flatten().cpu(), generated_ys[mask].flatten().cpu())\n",
    "\n",
    "            for s, g in zip(sm, list(generated_ys.cpu().numpy())):\n",
    "                vals[s] = g\n",
    "            \n",
    "            before_mse += raw_mse\n",
    "            running_mse += mse\n",
    "            global_step += 1\n",
    "\n",
    "    with open(save_location+'{}_dict.csv'.format(e), 'w') as csv_file:  \n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in vals.items():\n",
    "            writer.writerow([key, value])\n",
    "\n",
    "    return running_mse / global_step, before_mse / global_step\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import optuna\n",
    "from sdt import SDT\n",
    "from diffusion import GaussianMultinomialDiffusion\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "from ema import EMA\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float(\n",
    "        \"lr\", 1e-5, 1e-2, log=True\n",
    "    ) #0.0005\n",
    "\n",
    "    wd = trial.suggest_float(\n",
    "        \"wd\", 1e-5, 1e-2, log=True\n",
    "    ) #1e-4\n",
    "\n",
    "    warmup = trial.suggest_categorical(\n",
    "        \"warmup\", [50, 100, 150, 200, 250, 300]\n",
    "    ) #200\n",
    "\n",
    "    gamma = trial.suggest_float(\n",
    "        \"gamma\", 0.97, 0.999, log=True\n",
    "    ) #0.994\n",
    "\n",
    "    total_num_steps = (steps_per_epoch * num_epochs)\n",
    "\n",
    "    model = SDT(\n",
    "        time_dim = trial.suggest_categorical(\n",
    "            \"time_dim\", [16, 32, 64]\n",
    "        ), #64,\n",
    "        cond_size = 768,\n",
    "        patch_size = trial.suggest_categorical(\n",
    "            \"patch_size\", [8, 16, 32, 64]\n",
    "        ), #16\n",
    "        y_dim = NUMERICAL+15*(NUMERICAL+CATEGORICAL),\n",
    "        dim = 768,\n",
    "        depth = trial.suggest_int(\n",
    "            \"depth\", 4, 12\n",
    "        ), #8,\n",
    "        heads = trial.suggest_int(\n",
    "            \"heads\", 4, 12\n",
    "        ), #8,\n",
    "        mlp_dim = trial.suggest_categorical(\n",
    "            \"mlp_dim\", [256, 512, 768, 1024]\n",
    "        ), #768,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = trial.suggest_float(\n",
    "            \"emb_dropout\", 0, 0.2\n",
    "        ), #0.1,\n",
    "        num_classes = 15,\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Number of parameters: {total_params}\")\n",
    "\n",
    "    diffusion = GaussianMultinomialDiffusion(\n",
    "        num_classes = np.array([15 for _ in range(NUMERICAL+CATEGORICAL)]),\n",
    "        num_numerical_features = NUMERICAL,\n",
    "        denoise_fn = model,\n",
    "        device = device,\n",
    "    )\n",
    "    diffusion.to(device)\n",
    "\n",
    "    ema = EMA(diffusion, gamma, total_num_steps)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=wd,\n",
    "        )\n",
    "\n",
    "    lr_scheduler = get_scheduler(\n",
    "            trial.suggest_categorical(\n",
    "                \"schedule\", \n",
    "                [\n",
    "                    \"cosine\", \n",
    "                    \"linear\", \n",
    "                    \"cosine_with_restarts\", \n",
    "                    \"constant\", \n",
    "                    \"constant_with_warmup\",\n",
    "                ]\n",
    "            ), #\"cosine\",\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=warmup,\n",
    "            num_training_steps=total_num_steps,\n",
    "        )\n",
    "    \n",
    "    l = \"\"\n",
    "    loss = 0\n",
    "    for e in range(num_epochs):\n",
    "        loss = train(diffusion, ema, gamma, trainloader, optimizer, lr_scheduler)\n",
    "\n",
    "    mse, bmse = evaluate(e, ema, valloader)\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:02:33,251] Using an existing study with name '2024-10-25-optimize-ximagand' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an existing study with name '2024-10-25-optimize-ximagand' instead of creating a new one.\n",
      "Number of parameters: 19334528\n",
      "torch.Size([180])\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:04:37,527] Trial 7 finished with value: 23.35610762237664 and parameters: {'lr': 0.0022843538000994427, 'wd': 0.0002708728156692418, 'warmup': 200, 'gamma': 0.9772592840217776, 'time_dim': 16, 'patch_size': 32, 'depth': 6, 'heads': 8, 'mlp_dim': 256, 'emb_dropout': 0.11221196434678829, 'schedule': 'cosine'}. Best is trial 1 with value: 23.05985780360234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 finished with value: 23.35610762237664 and parameters: {'lr': 0.0022843538000994427, 'wd': 0.0002708728156692418, 'warmup': 200, 'gamma': 0.9772592840217776, 'time_dim': 16, 'patch_size': 32, 'depth': 6, 'heads': 8, 'mlp_dim': 256, 'emb_dropout': 0.11221196434678829, 'schedule': 'cosine'}. Best is trial 1 with value: 23.05985780360234.\n",
      "Number of parameters: 19977536\n",
      "torch.Size([180])\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:06:28,114] Trial 8 finished with value: 27.68829737941495 and parameters: {'lr': 0.006556702953383152, 'wd': 0.0007352947882873483, 'warmup': 200, 'gamma': 0.9945809272965487, 'time_dim': 64, 'patch_size': 64, 'depth': 7, 'heads': 4, 'mlp_dim': 512, 'emb_dropout': 0.16841374802502804, 'schedule': 'constant'}. Best is trial 1 with value: 23.05985780360234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 finished with value: 27.68829737941495 and parameters: {'lr': 0.006556702953383152, 'wd': 0.0007352947882873483, 'warmup': 200, 'gamma': 0.9945809272965487, 'time_dim': 64, 'patch_size': 64, 'depth': 7, 'heads': 4, 'mlp_dim': 512, 'emb_dropout': 0.16841374802502804, 'schedule': 'constant'}. Best is trial 1 with value: 23.05985780360234.\n",
      "Number of parameters: 30980064\n",
      "torch.Size([180])\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:10:14,026] Trial 9 finished with value: 27.20049802370143 and parameters: {'lr': 0.0016032044267986147, 'wd': 0.0031863420007909316, 'warmup': 250, 'gamma': 0.9773325860687475, 'time_dim': 64, 'patch_size': 16, 'depth': 7, 'heads': 10, 'mlp_dim': 768, 'emb_dropout': 0.0967484451063124, 'schedule': 'constant'}. Best is trial 1 with value: 23.05985780360234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 finished with value: 27.20049802370143 and parameters: {'lr': 0.0016032044267986147, 'wd': 0.0031863420007909316, 'warmup': 250, 'gamma': 0.9773325860687475, 'time_dim': 64, 'patch_size': 16, 'depth': 7, 'heads': 10, 'mlp_dim': 768, 'emb_dropout': 0.0967484451063124, 'schedule': 'constant'}. Best is trial 1 with value: 23.05985780360234.\n",
      "Number of parameters: 26486240\n",
      "torch.Size([180])\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:13:31,791] Trial 10 finished with value: 25.389050038880328 and parameters: {'lr': 0.0005399189675222774, 'wd': 0.002858478810613319, 'warmup': 100, 'gamma': 0.9920612264745521, 'time_dim': 32, 'patch_size': 16, 'depth': 6, 'heads': 10, 'mlp_dim': 768, 'emb_dropout': 0.01990798583329503, 'schedule': 'constant'}. Best is trial 1 with value: 23.05985780360234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 25.389050038880328 and parameters: {'lr': 0.0005399189675222774, 'wd': 0.002858478810613319, 'warmup': 100, 'gamma': 0.9920612264745521, 'time_dim': 32, 'patch_size': 16, 'depth': 6, 'heads': 10, 'mlp_dim': 768, 'emb_dropout': 0.01990798583329503, 'schedule': 'constant'}. Best is trial 1 with value: 23.05985780360234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-25 15:13:32,028] Trial 11 failed with parameters: {'lr': 1.4697450557892006e-05, 'wd': 3.480354635968786e-05, 'warmup': 150, 'gamma': 0.9981862245135316, 'time_dim': 32, 'patch_size': 32, 'depth': 4, 'heads': 12, 'mlp_dim': 1024, 'emb_dropout': 0.008672196331743487, 'schedule': 'reduce_lr_on_plateau'} because of the following error: ValueError(\"'reduce_lr_on_plateau' is not a valid SchedulerType\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_256404/2343495787.py\", line 76, in objective\n",
      "    lr_scheduler = get_scheduler(\n",
      "                   ^^^^^^^^^^^^^^\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/diffusers/optimization.py\", line 322, in get_scheduler\n",
      "    name = SchedulerType(name)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/enum.py\", line 744, in __call__\n",
      "    return cls.__new__(cls, value)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/enum.py\", line 1158, in __new__\n",
      "    raise ve_exc\n",
      "ValueError: 'reduce_lr_on_plateau' is not a valid SchedulerType\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 20959232\n",
      "torch.Size([180])\n",
      "Trial 11 failed with parameters: {'lr': 1.4697450557892006e-05, 'wd': 3.480354635968786e-05, 'warmup': 150, 'gamma': 0.9981862245135316, 'time_dim': 32, 'patch_size': 32, 'depth': 4, 'heads': 12, 'mlp_dim': 1024, 'emb_dropout': 0.008672196331743487, 'schedule': 'reduce_lr_on_plateau'} because of the following error: ValueError(\"'reduce_lr_on_plateau' is not a valid SchedulerType\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_256404/2343495787.py\", line 76, in objective\n",
      "    lr_scheduler = get_scheduler(\n",
      "                   ^^^^^^^^^^^^^^\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/site-packages/diffusers/optimization.py\", line 322, in get_scheduler\n",
      "    name = SchedulerType(name)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/enum.py\", line 744, in __call__\n",
      "    return cls.__new__(cls, value)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bhux/anaconda3/envs/s2pk/lib/python3.12/enum.py\", line 1158, in __new__\n",
      "    raise ve_exc\n",
      "ValueError: 'reduce_lr_on_plateau' is not a valid SchedulerType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-10-25 15:13:32,029] Trial 11 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'reduce_lr_on_plateau' is not a valid SchedulerType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m storage_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study_name)\n\u001b[1;32m      6\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39mstudy_name, storage\u001b[38;5;241m=\u001b[39mstorage_name, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(trial\u001b[38;5;241m.\u001b[39mvalue))\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[8], line 76\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     68\u001b[0m ema \u001b[38;5;241m=\u001b[39m EMA(diffusion, gamma, total_num_steps)\n\u001b[1;32m     70\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[1;32m     71\u001b[0m         model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     72\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     73\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mwd,\n\u001b[1;32m     74\u001b[0m     )\n\u001b[0;32m---> 76\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mget_scheduler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mschedule\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine_with_restarts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant_with_warmup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreduce_lr_on_plateau\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#\"cosine\",\u001b[39;49;00m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_warmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_training_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_num_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/site-packages/diffusers/optimization.py:322\u001b[0m, in \u001b[0;36mget_scheduler\u001b[0;34m(name, optimizer, step_rules, num_warmup_steps, num_training_steps, num_cycles, power, last_epoch)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_scheduler\u001b[39m(\n\u001b[1;32m    290\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, SchedulerType],\n\u001b[1;32m    291\u001b[0m     optimizer: Optimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m     last_epoch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    298\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LambdaLR:\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    Unified API to get any scheduler from its name.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m            The index of the last epoch when resuming training.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[43mSchedulerType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     schedule_func \u001b[38;5;241m=\u001b[39m TYPE_TO_SCHEDULER_FUNCTION[name]\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m SchedulerType\u001b[38;5;241m.\u001b[39mCONSTANT:\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/enum.py:744\u001b[0m, in \u001b[0;36mEnumType.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start, boundary, *values)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m names:\n\u001b[1;32m    743\u001b[0m         value \u001b[38;5;241m=\u001b[39m (value, names) \u001b[38;5;241m+\u001b[39m values\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# no body? no data-type? possibly wrong usage\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/s2pk/lib/python3.12/enum.py:1158\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m   1156\u001b[0m ve_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m is not a valid \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (value, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m))\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve_exc\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1160\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1161\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m._missing_: returned \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead of None or a valid member\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1162\u001b[0m             \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, result)\n\u001b[1;32m   1163\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: 'reduce_lr_on_plateau' is not a valid SchedulerType"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = \"2024-10-25-optimize-ximagand\"  # Unique identifier of the study.\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"minimize\", load_if_exists=True)\n",
    "study.optimize(objective, n_trials=900)\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Accuracy: {}\".format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "\n",
    "with open(\"2024-10-25-sampler.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study.sampler, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2pk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
